---
title: "Think Data"
subtitle: "An Introduction to Lists and Dictionaries"
jupyter: python3
filters:
  - qna
  - quarto
---

In this notebook we are going to look in more detail at how we can reduce, reuse, and recycle our code to make our lives easier and our code more efficient.

# Tackling Programming Problems

::: {.callout-note}

#### Connections

You will find links here to the Code Camp sessions on [Functions](https://jreades.github.io/code-camp/lessons/Functions.html) and [Packages](https://jreades.github.io/code-camp/lessons/Packages.html), as well as to this week's lectures on [Functions](https://jreades.github.io/fsds/sessions/week3.html#lectures) and [Packages](https://jreades.github.io/fsds/sessions/week3.html#lectures).

:::

::: {.callout-warning collapse="true"}

#### Difficulty: Medium.

:::

Let's now think about how to approach problems in programming (with code) and how that might differ from other ways of thinking. 

The problem we will use here as an example is: _download a data file that we know is hosted on a web site and output some information about those data_. This sounds hard. It _is_ hard when you're just starting out in programming. But it is _not_ hard for a computer... _iff_ we can figure out what to tell it to do _and_ make use of work that other people have done for us!

### What Do We Do? Break It Down!

#### Step 1. Analyse the Problem

The first step to writing a program is thinking about your goal and the steps required to achieve that. We _**don't**_ write programs like we write essays: all at once by writing a whole lot of code and then hoping for the best when we hit 'submit'.Â 

When you're tackling a programming problem you break it down into separate, simpler steps, and then tick them off one by one. Doing this gets easier as you become more familiar with programming, but it remains crucial and, in many cases, good programmers in large companies spend more time on _design_ than they do on actual _coding_.

#### Step 2. Functions & Packages

We have discussed how _functions_ are a useful programming tool to enable us to re-use chunks of code. Basically, a function is a way to do something to something in a portable, easy-to-use little bundle of code. 

Some steps in a program are done so many times by so many people that, eventually, someone writes a _package_ that bundles up those operations into something easy to use that saves _you_ having to figure out the gory details. Reading a file (even one on a computer halfway round the world) is one of those things. Making sense of the data *in* that file for you is probably not.

![xkcd: Easy vs. Hard](https://imgs.xkcd.com/comics/tasks.png)

To a computer, reading data from a remote location (e.g. a web site halfway around the world) is not really any different from reading one that's sitting on your your local hard drive (e.g. on your desktop). To simplify things a great deal: the computer really just needs to know the location of the file and an appropriate _protocol_ for accessing that file (_e.g._ http, https, ftp, local...) and then a clever programming language like Python will typically have packages that can kind of take of the rest. 

In all cases -- local and remote -- you use the package to handle the hard bit of knowing how to actually 'read' data (because all files are just `1`s and `0`s of data) at the _device_ level and then Python gives you back a 'file handle' that helps you to achieve things like 'read a line' or 'close an open file'. You can think of a filehandle as something that gives you a 'grip' on a file-like object no matter where or what it is, and the package is the way that this magic is achieved.

#### Step 3. Look for Ways to Recycle

**Always** look for ways to avoid reinventing the wheel. This is where Python's packages (or R's for that matter) come into their own. If it's something that programmers often need to do, then chances are that someone has written a package to do it!

The point of packages is that they can help us to achieve quite a lot very quickly since we can just make use of someone else's code. In the same way that we won't mark you down for Googling the answer to a coding question, we _also_ won't mark you down for using someone else's package to help you get going with your programming. _**That's the whole point!**_

Often, if you're not sure where to start, Google (or StackOverflow) is the place to go:

[`how to read text file on web server python`](https://www.google.co.uk/search?q=how+to+read+text+file+on+web+server+python&oq=how+to+read+text+file+on+web+server+python&aqs=chrome..69i57.629j0j7&sourceid=chrome&ie=UTF-8)

Boom!

#### Step 4. Make a Plan

OK, so we need to break this _hard_ problem down into something simpler. We can do this by thinking about it as three separate steps:

1. We want to read a remote file (i.e. a text file somewhere the planet), 
2. We want to turn it into a local data structure (i.e a list or a dictionary), 
3. We want to perform some calculations on the data (e.g. calculate the mean, find the easternmost city, etc.).

We can tackle each of those in turn, getting the first bit working, then adding the second bit, etc. It's just like using lego to build something: you take the same pieces and assemble them in different ways to produce different things.

## Reading a Remote File

So, we are going to [download a file from GitHub](https://github.com/jreades/fsds/blob/master/data/src/Wikipedia-Cities-simple.csv), but we **aren't going to to try to turn it into data** or otherwise make 'sense' of it yet, we just want to **read** it. We are then going to build from this first step towards the rest of the steps!

Because we're accessing data from a 'URL' we need to use the `urlopen` [function](https://docs.python.org/3.0/library/urllib.request.html?highlight=urlopen#urllib.request.urlopen) from the `urllib.request` [package](https://docs.python.org/3.0/library/urllib.request.html). If you're wondering how we know to use this function and package, you might google something like: _read remote csv file python 3_ which in turn might get you to a StackOverflow question and answer like [this](https://stackoverflow.com/questions/36965864/opening-a-url-with-urllib-in-python-3). 

<style type="text/css">
.longform {
    max-height: 500px;
    overflow-y: scroll;
}
</style>

::: {.longform}

```{python}
from urllib.request import urlopen
help(urlopen)
```

:::

As you can see, there is _lot_ of information here about how things work. A _lot_ of it won't make much sense at the moment. That's ok. _Some_ of this doesn't make much sense to me, but that's because this is the _full_ documentation from Python so it's trying to cover _all_ the bases. You don't need to read every line of this, what you are looking is information about things like the 'signature' (what parameters the function accepts) and its output. Of course, you can also _just Google it_!

::: {.callout-tip}

Remember that you can use `dir(...)` and `help(...)` to investigate what a package offers. You can also get help in Jupyter by typing `?` before the function that you want to call.

:::

::: {.callout-warning collapse="true"}

#### URLError?

If you are working behind a firewall (esp. if working on this practical in, say, China) then there is a *chance* you will get a `URLError` (`<urlopen error [Errno 110044] getaddrinfo failed>`). This is a '[proxy error](https://stackoverflow.com/questions/7334199/getaddrinfo-failed-what-does-that-mean)' and in this case you may need to [configure your environment](https://stackoverflow.com/a/28153935) as follows:

```
import os
os.environ['HTTP_PROXY'] = 'http://127.0.0.1:10809'
os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:10809'
```

:::

Before you start working on the code, why not open the data file [directly in your browser](https://raw.githubusercontent.com/jreades/fsds/master/data/src/Wikipedia-Cities-simple.csv)? It's pretty small, and it will give you a sense of what is going on.

```{python}
#| echo: false

from urllib.request import URLError
from urllib.request import urlopen

try:
    url = 'https://raw.githubusercontent.com/jreades/fsds/master/data/src/Wikipedia-Cities-simple.csv'
    response = urlopen(url)
    raw  = response.read()
    data = raw.decode('utf-8')
    urlData = data
except URLError as e:
    print("Unable to connect to URL!")
    print(e)
    with open('../data/src/Wikipedia-Cities-simple.csv', 'r') as f:
        data = f.read()
    urlData = data
```

```python
from urllib.request import URLError
from urllib.request import urlopen

# Given the info you were given above, what do you 
# think the value of 'url' should be? What
# type of variable is it? int or string? 
url = 'https://raw.githubusercontent.com/jreades/fsds/master/data/src/Wikipedia-Cities-simple.csv'

# Read the URL stream into variable called 'response'
# using the function that we imported above
try:
    response = urlopen(url)
except URLError as e:
    print("Unable to connect to URL!")
    print(e)

# You might want to explore what `__class__` and `__name__`
# are doing, but basically the give us a way of finding out what
# is 'behind' more complex variables

# Now read from the stream, decoding so that we get actual text
raw = response.read()

print(f"'raw' variable is of type: '{raw.__class__.__name__}'.")
print(f"Raw content is:\n{raw[:75]}...\n")

data = raw.decode('utf-8')

print(f"'data' variable is of type: '{data.__class__.__name__}'.")
print(f"Decoded content is:\n{data[:75]}...")
```

::: {.callout-note}

Notice that the `raw` data has the format `b'...'` with all of the data seemingly on one line, while the _decoded_ version in `data` is 'correctly' structured with lines! The 'raw' data is in _bytecode_ format which is not, strictly, a `string`. It only becomes a string when we 'decode it' to `utf-8` (which is the 'encoding' of text that supports most human languages). While the computer doesn't particularly care, we do!

:::

Remember that you can treat strings *as lists*, so when we `print` below we cut off the output using the `list[:<Some Number>]` syntax.

```{python}
print(f"There are {len(data)} characters in the data variable.")
print(f"The first 125 characters are: '{data[:125]}'") # Notice that '\n' count here!
```

So this is definitely text, but it doesn't (yet) look entirely like the data *we* see because it's still just one long string, and not *data* which has individual records on each line. To split the text into individual lines, we can use the handily named `.splitlines()` method (more on methods below):  

:::: {.qna}

#### Question

```python
rows = ??.splitlines()
print(f"'rows' variable is of type: {rows.__class__.__name__}'.")
```

#### Answer

```{python}
rows = data.splitlines()
print(f"'rows' variable is of type: {rows.__class__.__name__}'.")
```

::::

Note now, how the _data_ variable has type `list`. So to view the data as we see them in the original online file, we can now use a `for` loop to print out each element of the `list` (each element being a row of the original online file):

:::: {.qna}

#### Question

```python
print(f"There are {??} rows of data.")
print("\n".join(??[0:2])) # New syntax alert! notice we can *join* list elements
```

#### Answer

```{python}
print(f"There are {len(rows)} rows of data.")
print("\n".join(rows[0:2])) # New syntax alert! notice we can *join* list elements
```

::::

That's a little hard to read, though something has clearly changed. Let's try printing the last row:

```{python}
print(rows[-1])
```

**Congratulations!** You've now read a text file sitting on a server in, I think, Canada and Python _didn't care_. You've also converted a plain-text file to a row-formatted list.

## Text into Data

We now need to work on turning the response into useful data. We got partway there by splitting on line-breaks (`splitlines()`), but now we need to get columns for each line. You'll notice that we are dealing with a _CSV_ (Comma-Separated Value) file and that the format _looks_ quite simple... So, in theory, to turn this into data we 'just' need to _split_ each row into separate fields using the commas.

There's a handy function associated with strings called `split`:

```{python}
print('abcdefgh'.split('d'))
```

You can also investigate further how the split function works using:

```{python}
help('abcdefgh'.split)
```

So this seems like a good solution to turn our text into *data*:

```{python}
test = rows[-1].split(',')
print(test)
print(f"The population of {test[0]} is {int(test[1]):,}")
```

I'd say that we're now getting quite close to something that looks like 'real data': I know how to convert a raw response from a web server into a string, to split that string into rows, and can even access individual elements from a row! 

## The Advantages of a Package

::: {.callout-caution}

There are two problems to the `data.splitlines()` and `row.split(',')` approach! One of them is visible (though not obvious) in the examples above, the other is not.

:::

1. Remember that `10` and `'10'` are _not_ the same thing. To comma-format the population of Sheffield you'll see that I had to do `int(...)` in order to turn `'685368'` into a number. So our approach so far doesn't know anything about the _type_ of data we're working with.
2. We are also implicitly _assuming_ that commas can only appear at field boundaries (i.e. that they can only appear to separate one column of data from the next). In other words, just using `split(',')` doesn't work if *any* of the fields can themselves contain a comma!
3. There's actually a _third_ potential issue, but it's so rare that we would need to take a completely different approach to deal with it: we are also assuming that newlines (`\n`) can only appear at record boundaries (i.e. that the can only appear to separate one row of data from the next). In those cases, using `splitlines()` also doesn't work, but this situation is (thankfully) very rare indeed.

This is where using code that someone _else_ who is much more interested (and knowledgeable) has written and contributed is helpful: we don't need to think through how to deal with this sort of thing ourselves, we can just find a library that does what we need and make use of _its_ functionality. I've given you the skeleton of the answer below, but you'll need to do a little Googling to find out how to `"read csv python"`. 

**Note:** For now just focus on problem \#2.

```python
from urllib.request import urlopen
import csv

url = 'https://raw.githubusercontent.com/jreades/fsds/master/data/src/Wikipedia-Cities-simple.csv'
response = urlopen(url)
raw = response.read()

# Now take the raw data, decode it, and then
# pass it over to the CSV reader function
csvfile  = csv.reader(raw.decode('utf-8').splitlines()) 

urlData = [] # Somewhere to store the data
for row in csvfile:              
    urlData.append( row )

print("urlData has " + str(len(urlData)) + " rows and " + str(len(urlData[0])) + " columns.")
print(urlData[-1]) # Check it worked!
```

```{python}
#| echo: false
urlData = [x.split(",") for x in urlData.splitlines()]
```

If it worked, then you should have this output:

```{python}
#| echo: false
print("urlData has " + str(len(urlData)) + " rows and " + str(len(urlData[0])) + " columns.")
print(str(urlData[-1]))
```

To you that might look a lot _worse_ that the data that you originally had, but to a computer that list-of-lists is something it can work with; check it out:

```{python}
for u in urlData[1:6]: # For each row in the first 5 items in list
    print(f"The city of '{u[0]}' has a population of {int(u[1]):,}") # Print out the name and pop
```

::: {.callout-note}

Why did I use `urlData[1:]` instead of `urlData`?

If you print `urlData[0]` you'll see that this is the 'header' row that tells us what each column contains! So if we try to convert the column name to an integer (`int(u[1])`) we will get an error!

The advantage of using the `csv` library over plain old `string.split` is that the csv library knows how to deal with fields that contain commas (_e.g._ `"Cardfiff, Caerdydd"` or `"An Amazing 4 Bedroom Home, Central London, Sleeps 12"`) and so is much more flexible and consistent that our naive `split` approach. The vast majority of _common_ tasks (reading certain types of files, getting remote files, etc.) have libraries that do exactly what you want without you needing to write much code yourself to take advantage of it. You should always have a look around online to see if a library exists before thinking that you need to write everything/anything from scratch. The tricky part is knowing what words to use for your search and how to read the answers that you find...

:::

Let's try this with a 'bigger' data set... In an ideal world, the 'power' of code is that once we've solved the problem *once*, we've solved it more generally as well. So let's try with the 'scaled-up' data set and see waht happens!

```python
from urllib.request import urlopen
import csv

url = "https://raw.githubusercontent.com/jreades/fsds/master/data/src/Wikipedia-Cities.csv"
response = urlopen(url)
raw = response.read()

csvfile = csv.reader(raw.decode('utf-8').splitlines())

urlData = [] # Somewhere to store the data

for row in csvfile:              
    urlData.append( row )

print(f"urlData has {len(urlData)} rows and {len(urlData[0])} columns.")

for u in urlData[70:]:  # For each row in the list
    print(f"The city of '{u[0]}' has a population of {u[1]}") # Print out the name and pop
```

::: {.callout-warning collapse="true"}

#### What mistake have I made here?

I have assumed that, just because the files have similar names, they must also have similar layouts!

```{python}
print(f"The URL's data labels are: {', '.join(urlData[0])}")
```

:::

## Insight!

So, although the code was basically the same for both of these files (good), we would need to change quite a bit in order to print out the _same_ information from different versions of the _same data_. So our code is rather **brittle**.

One of the issues is that our _instincts_ about how to manage data doesn't align with how the computer can most _efficiently_ manage it. We make the mistake of thinking that the computer needs to do things that same way that we do when reading text and so assume that we need to:

1. Represent the rows as a list.
2. Represent the columns as a list for each row.

This thinking suggests that the 'right' data structure would clearly be a list-of-lists (LoLs!), but if you understand what happened here then the next section will make a _lot_ more sense!

# Why 'Obvious' is Not Always 'Right'

::: {.callout-note}

#### &#128279; Connections

This section builds on the material covered by the [DOLs to Data](https://jreades.github.io/fsds/sessions/week3.html#lectures) lecture.

:::

::: {.callout-caution collapse="true"}

#### Difficulty: Hard.

:::

But you need to be careful assuming that, just because something is hard for you to read, it's also hard for a computer to read! The way a computer 'thinks' and the way that we think doesn't always line up naturally. Experienced programmers can think their way _around_ a problem by working _with_ the computer, rather than against it.

Some issues to consider:

- Is the first row of data _actually_ data, or is it _about_ data?
- Do we really care about column _order_, or do we just care about being able to pick the _correct_ column?

Let's apply this approach to the parsing of our data...

## Understanding What's an 'Appropriate' Data Structure

If you stop to think about it, then our list-of-lists approach to the data isn't very easy to navigate. Notice that if the position or name of a column changes then we need to change our program _every_ time we re-run it! It's not very easy to read *either* since we don't really know what `u[5]` is supposed to be. That way lies all kinds of potential errors!

Also consider that, in order to calculate out even a simple aggregate such as the `sum` of a field for all rows we need to step through a lot of irrelevant data as well: we have to write a `for` loop and then step through each row with an 'accumulator' (somewhere to store the total). That's slow. 

That doesn't make much sense since this should all be _easier_ and _faster_ in Python than in Excel, but right now it's _harder_, and quite possibly _slower_ as well! So how does the experienced programmer get around this? 'Simple' (i.e. neither simple, nor obvious, until you know the answer): she realises that the data is organised the wrong way! We humans tend to think in rows of data: this apartment has the following _attributes_ (price, location, etc.), or that city has the following _attributes_ (population, location). We read across the row because that's the easiest way for *us* to think about it. But, in short, a list-of-lists does _not_ seem to be the right way to store this data!

Crucially, a computer doesn't have to work that way. For a computer, it's as easy to read _down_ a column as it is to read _across_ a row. **In fact, it's easier**, because each column has the same _type_ of data: one column contains names (strings), another column contains prices (integers), and other columns contain other types of data (floats, etc.). Better still, the order of the columns often doesn't matter as long as we know what the columns are called: it's easier to ask for the 'description column' than it is to ask for the 6th column since, for all we know, the description column might be in a different place for different files but they are all (relatively) likely to use the 'description' label for the column itself.

### A Dictionary of Lists to the Rescue

So, if we don't care about column order, only row order, then a dictionary of lists would be a nice way to handle things. And why should we care about column order? With our CSV files above we already saw what a pain it was to fix things when the layout of the columns changed from one data set to the next. If, instead, we can just reference the 'description' column then it doesn't matter where that column actually is. Why is that? 

Well, here are the first four rows of data from a list-of-lists for city sizes:

```python
myData = [
  ['id', 'Name', 'Rank', 'Longitude', 'Latitude', 'Population'], 
  ['1', 'Greater London', '1', '-18162.92767', '6711153.709', '9787426'], 
  ['2', 'Greater Manchester', '2', '-251761.802', '7073067.458', '2553379'], 
  ['3', 'West Midlands', '3', '-210635.2396', '6878950.083', '2440986']
]
```

Now, here's how it would look as a dictionary of lists organised by _column_, and _not_ by row:

```{python}
#| echo: true
myData = {
    'id'         : [0, 1, 2, 3, 4, 5],
    'Name'       : ['London', 'Manchester', 'Birmingham','Edinburgh','Inverness','Lerwick'],
    'Rank'       : [1, 2, 3, 4, 5, 6],
    'Longitude'  : [-0.128, -2.245, -1.903, -3.189, -4.223, -1.145],
    'Latitude'   : [51.507, 53.479, 52.480, 55.953, 57.478, 60.155],
    'Population' : [9787426, 2705000, 1141816, 901455, 70000, 6958],
}

print(myData['Name'])
print(myData['Population'])
```

What does this do better? Well, for starters, we know that everything in the 'Name' column will be a string, and that everything in the 'Longitude' column is a float, while the 'Population' column contains integers. So that's made life easier already, but the real benefit is coming up...

### Behold the Power of the DoL

Now let's look at what you can do with this... but first we need to import one _more_ package that you're going to see a _lot_ over the rest of term: `numpy` (Numerical Python), which is used _so_ much that most people simply refer to it as `np`. This is a _huge_ package in terms of features, but right now we're interested only in the basic arithmatic functions: `mean`, `max`, and `min`.

::: {.callout-tip collapse="true"}

#### We'll step through most of these in detail below.

:::

Find the latitude of Manchester:

```{python}
city = "Manchester"
lat = myData['Latitude'][ myData['Name'].index(city) ]
print(f"{city}'s latitude is {lat}")
```

Print the location of Lerwick:

:::: {.qna}

#### Question

```python
city = "Lerwick"
print(f"The town of {city} can be found at " + 
      f"{abs(myData[??][ ?? ])}ÂºW, {myData['Latitude'][ ?? ]}ÂºN")
```

#### Answer

```{python}
city = "Lerwick"
print(f"The town of {city} can be found at " + 
      f"{abs(myData['Longitude'][myData['Name'].index(city)])}ÂºW, {myData['Latitude'][myData['Name'].index(city)]}ÂºN")
```

::::

Find the easternmost city:

:::: {.qna}

#### Question

```python
city = myData['Name'][ myData[??].index( max(myData[??]) ) ]
print(f"The easternmost city is: {city}")
```

#### Answer

```{python}
city = myData['Name'][ myData['Longitude'].index( max(myData['Longitude']) ) ]
print(f"The easternmost city is: {city}")
```

::::

Find the `mean` population of the cities using a handy package called numpy:

::: {.qna}

#### Question

```python 
import numpy as np
mean = np.??(myData['Population'])
print(f"The mean population is: {mean}")
```

#### Answer

```{python}
import numpy as np
mean = np.mean(myData['Population'])
print(f"The mean population is: {mean}")
```

::::

::: {.callout-warning}

**Stop!** Look closely at what is going on. There's a _lot_ of content to process in the code above, so do _not_ rush blindly on if this is confusing. Try pulling it apart into pieces and then reassemble it. Start with the bits that you understand and then *add* complexity.

:::

We'll go through each one in turn, but they nearly all work in the same way and the really key thing is that you'll notice that we no longer have any loops (which are slow) just `index` or `np.<function>` (which is _very_ fast). 

### The Population of Manchester

The code can look pretty daunting, so let's break it down into two parts. What would you get if you ran just this code?

```{python}
myData['Population'][1]
```

```{python}
#| echo: false
o1 = myData['Population']
o2 = myData['Population'][1]
```

Remember that this is a dictionary-of-lists (DoL). So, Python first looks for a key named `Population` in the myData dictionary. It finds out that the value associated with this key is a _list_ and in this example, it just pulls out the second value (index `1`). Does **that part** make sense?

Now, to the second part:

```{python}
myData['Name'].index('Manchester')
```

Here we look in the dictionary for the key `Name` and find that that's _also_ a list. All we're doing here is asking Python to find the index of 'Manchester' for us in that list. And `myData['Name'].index('Manchester')` gives us back a `1`, so _instead_ of just writing `myData['Population'][1]` we can replace the `1` with `myData['Name'].index('Manchester')`! Crucially, notice the complete _absence_ of a for loop?

Does that make sense? If it does then you should be having a kind of an &#129327; moment because what we've done by taking a column view, rather than a row view, is to make Python's `index()` command do the work for us. Instead of having to look through each row for a field that matches 'Name' and then check to see if it's 'Manchester', we've pointed Python at the right column immediately and asked it to find the match (which it can do very quickly). Once we have a match then we _also_ have the row number to go and do the lookup in the 'Population' column because the index _is_ the row number!

### The Easternmost City

Where this approach really comes into its own is on problems that involve maths. To figure out the easternmost city in this list we need to find the _maximum_ Longitude and then use _that_ value to look up the city name. So let's do the same process of pulling this apart into two steps. Let start with the easier bit:

```{python}
myData['Name'][0]
```

That would give us the name of a city, but we don't just want the first city in the list, we want the one with the maximum longitude. To achieve _that_ we need to somehow replace the `0` with the _**index of the maximum longitude**_. Let's break this down further: 

1. We first need to _find_ the maximum longitude.
2. We then need to _find_ the **index** of that maximum longitude.

So Step 1 would be:

```{python}
max_lon = max(myData['Longitude'])
```

Because the `max(...)` helps us to find the maximum longitude in the Longitude list. Now that we have that we can proceed to Step 2:

```{python}
myData['Longitude'].index(max_lon)
```

So now we ask Python to find the position of `max_lon` in the list. But rather than doing this in two steps we can combine into one if we write it down to make it easier to read:

```{python}
myData['Longitude'].index(
    max(myData['Longitude'])
)
```

There's the same `.index` which tells us that Python is going to look for something in the list associated with the `Longitude` key. All we've done is change what's _inside_ that index function to `max(myData['Longitude'])`. This is telling Python to find the _maximum_ value in the `myData['Longitude']` list. So to explain this in three steps, what we're doing is:

- Finding the maximum value in the Longitude column (we know there must be one, but we don't know what it is!),
- Finding the index (position) of that maximum value in the Longitude column (now that we know what the value is!),
- Using that index to read a value out of the Name column.

I _am_ a geek, but that's pretty cool, right? In one line of code we managed to quickly find out where the data we needed was even though it involved three discrete steps. Think about how much work you'd have to do if you were still thinking in _rows_, not _columns_!

### The Location of Lerwick

Lerwick is a small town in [the Shetlands](https://www.shetland.org/), way up to the North of mainland U.K. and somewhere I've wanted to go ever since I got back from [Orkney](https://www.orkney.com/)--but then I spent my honeymoon in the far North of [Iceland](https://www.westfjords.is/), so perhaps I just don't like being around lots of people... ðŸ™ƒ

Anyway, this one _might_ be a tiny bit easier conceptually than the other problems, except that I've deliberately used a slightly different way of showing the output that might be confusing:

Print the location of Lerwick:

```{python}
city = "Lerwick"
print(f"The town of {city} can be found at " + 
      f"{abs(myData['Longitude'][myData['Name'].index(city)])}ÂºW, {myData['Latitude'][myData['Name'].index(city)]}ÂºN")
```

The first thing to do is to pull apart the `print` statement: you can see that this is actually just two 'f-strings' joined by a `+`--having that at the end of the line tells Python that it should carry on to the next line. That's a handy way to make your code a little easier to read. If you're creating a list and it's getting a little long, then you can also continue a line using a `,` as well!

#### 1. The first f-string
   
The first string will help you to make sense of the second: f-strings allow you to 'interpolate' a variable into a string directly rather than having to have lots of `str(x) + " some text " + str(y)`. You can write `f"{x} some text {y}"` and Python will automatically convert the variables `x` and `y` to strings and replace `{x}` with the _value of `x`_ and `{y}` with the _value of `y`_. 

So here `f"The town of {city} can be found at "` becomes `f"The town of Lerwick can be found at "` because `{city}` is replaced by the value of the variable `city`. This makes for code that is easier for humans to read and so I'd consider that a good thing.

#### 2. The second f-string
This one is hard because there's just a _lot_ of code there. But, again, if we start with what we recognise that it gets just a little bit more manageable... Also, it stands to reason that the only difference between the two outputs is that one asks for the 'Longitude' and the other for the 'Latitude'. So if you can make sense of one you have _automatically_ made sense of the other and don't need to work it all out.

Let's start with a part that you might recognise:

```{python}
myData['Name'].index(city)
```

You've _got_ this. This is just asking Python to work out the index of Lerwick (because `city = 'Lerwick'`). So it's a number. 5 in this case. And we can then think, 'OK so what does this return:

```{python}
myData['Longitude'][5]
```

```{python}
#| echo: false
o3 = myData['Longitude'][5]
```

And the answer is `-1.145`. That's the Longitude of Lerwick! There's just _one_ last thing: notice that we're talking about degrees West here. So the answer isn't a negative (because negative West degrees would be _East_!), it's the _absolute_ value. And that is the final piece of the puzzle: `abs(...)` gives us the absolute value of a number!

```{python}
help(abs)
```

### The Average City Size

Here we're going to 'cheat' a little bit: rather than writing our own function, we're going to import a package and use someone _else's_ function. The `numpy` package contains a _lot_ of useful functions that we can call on (if you don't believe me, add "`dir(np)`" on a new line after the `import` statement), and one of them calculates the average of a list or array of data.

```{python}
print(f"The mean population is {np.mean(myData['Population'])}")
```

This is where our new approach really comes into its own: because all of the population data is in one place (a.k.a. a _series_ or column), we can just throw the whole list into the `np.mean` function rather than having to use all of those convoluted loops and counters. Simples, right? 

No, not _simple_ at all, but we've come up with a way to _make_ it simple.

### Recap!

So the _really_ clever bit in all of this isn't switching from a list-of-lists to a dictionary-of-lists, it's recognising that the dictionary-of-lists is a _better_ way to work _with_ the data that we're trying to analyse and that that there are useful functions that we can exploit to do the heavy lifting for us. Simply by changing the way that we stored the data in a 'data structure' (i.e. complex arrangement of lists, dictionaries, and variables) we were able to do away with lots of for loops and counters and conditions, and reduce many difficult operations to something that could be done on one line! 

## Brain Teaser

::: {.callout-caution collapse="true"}

#### Difficulty: &#129327;.

:::

Why not have a stab at writing the code to print out the _4th most populous_ city? This can _still_ be done on one line, though you might want to start by breaking the problem down:

1. How do I find the _4th_ largest value in a list?
2. How do I find the _index_ of the 4th largest value in a list?
3. How do I use that to look up the name associated with that index?

You've already done \#2 and \#3 above so you've _solved_ that problem. If you can solve \#1 then the rest should fall into place.

::: {.callout-tip}

You don't want to use `<list>.sort()` because that will sort your data *in place* and break the link between the indexes across the 'columns'; you want to research the function `sorted(<list>)` where `<list>` is the variable that holds your data and `sorted(...)` just returns whatever you pass it in a sorted order *without* changing the original list. You'll see why this matters if you get the answer... otherwise, wait a few days for the answers to post.

:::

:::: {.qna}

#### Question

```python
# Print out the name of the 4th most populous city-region
city = ??

print("The fourth most populous city is: " + str(city))
```

#### Answer

```{python}
# Print out the name of the 4th most populous city-region
city = myData['Name'][
    myData['Population'].index(sorted(myData['Population'], reverse=True)[3])
]

print("The fourth most populous city is: " + str(city))
```

::::

```{python}
#| echo: false
#| output: asis
print(f"The answer is {city}.")
```

## Bringing it all together...

Conceptually, this is one of the hardest practicals in the entire term because it joins up so many of the seemingly simple ideas that you covered in Code Camp into a very complex 'stew' -- all our basic ingredients (lists, dictionaries, etc.) have simmered for a bit, been stirred up together, and become something entirely new and more complex.

So if this practical doesn't make sense to you on the _first_ runthrough, I'd suggest going back through the second half of the practical _again_ in a couple of days' time -- that will give your brain a little time to wrap itself around the basics before you throw the hard stuff at it again. _Don't_ panic if it doesn't all make sense on the _second_ runthrough either -- this is like a language, you need to practice! With luck, the second time you went through this code a little bit _more_ made sense. If you need to do it a third time you'll find that even _more_ makes sense... and so on. 

This is a very challenging notebook because it takes you *both* through the process of building a function incrementally *and* through a 'simple' example of how Python classes actually work. You will need to understand these two very different elements in order to make the most of the remaining 6 weeks of term, because we both improve our code incrementally *and* make use of objects and their inheritances extensively. You also get an extra chance to revisit the differences between LoLs and DoLs because you will undoubtedly encounter and make use of these data structures even *after* you become a skillfull Python programmer.

::: {.callout-warning}

This is a very challenging practical and you should do your best to ensure that you actually understand what you have done and why.

::: 

::: {.callout-tip}

#### Group Sign-Up

```{python}
#| echo: false
#| output: asis

print("You should now make it a priority [Sign Up]({{< var module.signup >}})!")
```

:::

# Why 'Obvious' is Not Always 'Right' (Revisited)

Practical 3 is hard, so I want to provide _another_ chance for the concepts to bed in before we use them in an *object-oriented way through Pandas*. Yes, Week 5 will show how we combine concepts covered over the preceding two weeks in *practice* to 'do data science'.

First, remember the finding from last week: if we don't really care about column order, then a dictionary of lists is a nice way to handle data. And why should we care about column order? With our CSV file we saw what a pain it was to fix things when even a tiny thing like the layout of the columns changed. But if, instead, we could just reference the 'Description' column in the data set then it doesn't matter where that column actually is *and* we would know that all the descriptions would be *text*, while all the populations or prices would be *numbers*. Why is that? 

::: {.callout-note}

#### &#128279; Connections

This task briefly recaps the final part of the previous practical and builds on the [DOLs to Data](https://jreades.github.io/fsds/sessions/week3.html#lectures) and [Functions](https://jreades.github.io/fsds/sessions/week4.html#lectures) lectures.

:::

## The Way That Doesn't Work

Recall that this is how four rows of 'data' for city sizes organised by _row_ as a list-of-lists look:

```{python}
myData = [
    ['id', 'Name', 'Rank', 'Longitude', 'Latitude', 'Population'], 
    ['1', 'Greater London', '1', '-18162.92767', '6711153.709', '9787426'], 
    ['2', 'Greater Manchester', '2', '-251761.802', '7073067.458', '2553379'], 
    ['3', 'West Midlands', '3', '-210635.2396', '6878950.083', '2440986']
]
```

To print out a list of every city in the data set *when* we don't know where the `Name` column is in the file we have to jump through some hoops:

```{python}
cities = []

col    = myData[0].index('Name')
for i in range(1, len(myData)):
    cities.append(myData[i][col])

print("The cities in the data set are: " + ", ".join(cities))
```

And it's the same kind of faff if we want to find out if `Edinburgh` is included in the data set:

```{python}
col   = myData[0].index('Name')
found = False
for i in range(1, len(myData)):
    if myData[i][col] == 'Edinburgh':
        print("Found Edinburgh in the data set!")
        found = True
        break

if found == False:
    print("Didn't find Edinburgh in the data set.")
```

## The Way That Does Work

Compare that code to how it works for a dictionary-of-lists organised by _column_. Now try printing out the cities in the data:

```{python}
myData = {
    'id'         : [0, 1, 2, 3, 4, 5],
    'Name'       : ['Greater London', 'Greater Manchester', 'Birmingham','Edinburgh','Inverness','Lerwick'],
    'Rank'       : [1, 2, 3, 4, 5, 6],
    'Longitude'  : [-0.128, -2.245, -1.903, -3.189, -4.223, -1.145],
    'Latitude'   : [51.507, 53.479, 52.480, 55.953, 57.478, 60.155],
    'Population' : [9787426, 2705000, 1141816, 901455, 70000, 6958],
}
```

To print out a list of every city in the data set:

```{python}
print(", ".join(myData['Name']))
```

To find out if `Edinburgh` is included in the list of data:

```{python}
if 'Edinburgh' in myData['Name']:
    print("Found Edinburgh in the data set!")
else:
    print("Didn't find Edinburgh in the data set.")
```

See how even basic questions like "Is Edinburgh in our list of data?" are suddenly easy to answer? We no longer need to loop over the entire data set in order to find one data point. In addition, we know that everything in the 'Name' column will be a string, and that everything in the 'Longitude' column is a float, while the 'Population' column contains integers. So that's made life easier already. But let's test this out and see how it works.

# Appending a Column

## Calculate Mean

Let's start by calculating the sample mean (use Google: `Python numpy mean...`):

```{python}
import numpy as np
# Use numpy functions to calculate mean and standard deviation
mean = np.mean(myData['Population'])
print(f"City distribution has a mean of {mean:,.0f}.")
```

## Calculate Standard Deviation

::: {.callout-tip collapse="true"}

#### Difficulty level: Low-ish.

:::

Now let's do the standard deviation:

:::: {.qna}

#### Question

```python
import numpy as np
# Use numpy functions to calculate mean and standard deviation
std  = np.??(??)
print(f"City distribution has a standard deviation of {std:,.2f}.")
```

#### Answer

```{python}
import numpy as np
# Use numpy functions to calculate mean and standard deviation
std  = np.std(myData['Population'])
print(f"City distribution has a standard deviation of {std:,.2f}.")
```

::::

So the `numpy` package gives us a way to calculate the mean and standard deviation _quickly_ and without having to reinvent the wheel. The other potentially new thing here is `{std:,.2f}`. This is about [string formatting](https://www.w3schools.com/python/ref_string_format.asp) and the main thing to recognise is that this means 'format this float with commas separating the thousands/millions and 2 digits to the right'. The link I've provided uses the slightly older approach of `<str>.format()` but the formatting approach is the same.

## For Loops Without For Loops

::: {.callout-warning collapse="true"}

#### Difficulty level: Medium.

:::

Now we're going to see something called a **List Comprehension**.

In Python you will see code like this a lot: `[x for x in list]`. This syntax is known as a 'list comprehension' and is basically a `for` loop on one line with the output being assigned to a list. So we can apply an operation (converting to a string, subtracting a value, etc.) to every item in a list without writing out a full for loop.

Here's a quick example just to show you what's going on:

```{python}
demo = range(0,10) # <- a *range* of numbers between 0 and 9 (stop at 10)
print([x**2 for x in demo]) # square every element of demo
```

Now let's apply this to our problem. We calculated the the mean and standard deviation above, so now we want to apply the z-score formula to every element of the Population list...  Remember that the format for the z-score (when dealing with a sample) is: 

$$
z = \frac{x - \bar{x}}{s}
$$

And the population standard deviation (by which I mean, if you are dealing with *all* the data, and not a subsample as we are here) is:

$$
z = \frac{x - \mu}{\sigma}
$$

:::: {.qna}

#### Question

```python
rs = [(x - ??)/?? for x in myData['Population']] # rs == result set
print([f"{x:.3f}" for x in rs])
```

#### Answer

```{python}
rs = [(x - mean)/std for x in myData['Population']] # rs == result set
print([f"{x:.3f}" for x in rs])
```

::::

## Appending

::: {.callout-tip collapse="true"}

#### Difficulty level: trivial

:::

And now let's add it to the data set:

```{python}
myData['Std. Population'] = rs
print(myData['Std. Population'])
```

And just to show how everything is in a single data structure:

```{python}
for c in myData['Name']:
    idx = myData['Name'].index(c)
    print(f"{c} has a population of {myData['Population'][idx]:,} and standardised score of {myData['Std. Population'][idx]:.3f}")
```

# 'Functionalising'

Let's start trying to pull what we've learned over the past two weeks together by creating a a set of functions that will help us to:

1. Download a file from a URL (checking if it has already _been_ downloaded to save bandwidth).
2. Parse it as a CSV file and...
3. Convert it to a Dictionary-of-Lists
4. Perform some simple calculations using the resulting data.

To be honest, there's not going to be much about writing our _own_ objects here, but we will be making use of them and, conceptually, an understanding of objects and classes is going to be super-useful for understanding what we're doing in the remainder of the term!

## Downloading from a URL

Let's focus on the first part *first* because that's the precondition for everything else. If we can get the 'download a file from a URL' working then the rest will gradually fall into place through *iterative* improvments!

### Finding an Existing Answer

::: {.callout-tip collapse="true"}

#### Difficulty level: Low

:::

First, let's be sensibly lazy--we've already written code to read a file from the Internet and turn it into a list of lists. So I've copy+pasted that into the code block below since we're going to start from this point; however, just to help you check your own understanding, I've removed a few bits and replaced them with `??`. Sorry, it's good practice. ðŸ˜ˆ

```{python}
#| echo: false

from urllib.request import URLError
from urllib.request import urlopen

try:
    url = 'https://raw.githubusercontent.com/jreades/fsds/master/data/src/Wikipedia-Cities-simple.csv'
    response = urlopen(url)
    raw  = response.read()
    data = raw.decode('utf-8')
    urlData = [ x.split(',') for x in data.splitlines() ]
except URLError as e:
    with open('../data/src/Wikipedia-Cities-simple.csv', 'r') as f:
        data = f.read()
    urlData = [ x.split(',') for x in data.splitlines() ]
```

:::: {.qna}

#### Question

```python
from urllib.request import urlopen
import csv

url = "https://raw.githubusercontent.com/jreades/fsds/master/data/src/Wikipedia-Cities-simple.csv"

urlData = [] # Somewhere to store the data

response = urlopen(url) #Â Get the data using the urlopen function
csvfile  = csv.reader(response.read().decode('utf-8').splitlines()) # Pass it over to the reader

for row in csvfile:
    urlData.append(??)

print("urlData has " + str(len(urlData)) + " rows and " + str(len(urlData[0])) + " columns.")
print(urlData[-1]) # Check it worked!
```

You should get: 

```{python}
#| echo: false
#| output: asis

print(f"<code>urlData has {len(urlData)} rows and {len(urlData[0])} columns.</code>")
print("<br />")
print(f"<code>{ urlData[-1] }</code>")
```

#### Answer

```python
from urllib.request import urlopen
import csv

url = "https://raw.githubusercontent.com/jreades/fsds/master/data/src/Wikipedia-Cities-simple.csv"

urlData = [] # Somewhere to store the data

response = urlopen(url) #Â Get the data using the urlopen function
csvfile  = csv.reader(response.read().decode('utf-8').splitlines()) # Pass it over to the reader

for row in csvfile:
    urlData.append(row)

print("urlData has " + str(len(urlData)) + " rows and " + str(len(urlData[0])) + " columns.")
print(urlData[-1]) # Check it worked!
```

::::

### Getting Organised

::: {.callout-tip collapse="true"}

#### Difficulty level: Low

:::

Let's take the code above and modify it so that it is:

1. A function that takes two arguments: a URL; and a destination filename.
2. Implemented as a function that checks if a file exists already before downloading it again.

You will find that the `os` module helps here because of the `path` function. And you will [need to Google](https://lmgtfy.app/?q=check+if+file+exists+python) how to test if a file exists. I would normally select a StackOverflow link in the results list over anything else because there will normally be an _explanation_ included of why a particular answer is a 'good one'. I also look at which answers got the most votes (not always the same as the one that was the 'accepted answer'). In this particular case, I also found [this answer](https://careerkarma.com/blog/python-check-if-file-exists/) useful.

I would start by setting my inputs:

```{python}
import os
url = "https://raw.githubusercontent.com/jreades/fsds/master/data/src/Wikipedia-Cities-simple.csv"
out = os.path.join('data','Wikipedia-Cities.csv') # Print `out` if you aren't sure what this has done!
```

### Sketching the Function

::: {.callout-tip collapse="true"}

#### Difficulty level: Low, if you've watched the videos...

:::

Then I would sketch out how my function will work using comments. And the simplest thing to start with is checking whether the file has already been downloaded:

:::: {.qna}

#### Question

```python
from urllib.request import urlopen

def get_url(src, dest):
    
    # Check if dest exists -- if it does
    # then we can skip downloading the file,
    # otherwise we have to download it!
    if os.path.isfile(??):
        print(f"{dest} found!")
    else:
        print(f"{dest} *not* found!")
        
get_url(url, out)
```

#### Answer

```{python}
from urllib.request import urlopen

def get_url(src, dest):

    # Check if dest exists -- if it does
    # then we can skip downloading the file,
    # otherwise we have to download it!
    if os.path.isfile(dest):
        print(f"{dest} found!")
    else:
        print(f"{dest} *not* found!")

get_url(url, out)
```

::::

### Fleshing Out the Function 

::: {.callout-warning collapse="true"}

#### Difficulty level: Medium

If you really explore what's going on in the function rather than just running it and moving on.

:::

I would then flesh out the code so that it downloads the file if it isn't found and then, either way, returns the *local* file path for our CSV reader to extract:

```{python}
def get_url(src, dest):
    
    # Check if dest does *not* exist -- that
    # would mean we had to download it!
    if os.path.isfile(dest):
        print(f"{dest} found locally!")
    else:
        print(f"{dest} not found, downloading!")
        
        #Â Get the data using the urlopen function
        response = urlopen(src) 
        filedata = response.read().decode('utf-8')
        
        # Extract the part of the dest(ination) that is *not*
        # the actual filename--have a look at how 
        # os.path.split works using `help(os.path.split)`
        path = list(os.path.split(dest)[:-1])
        
        # Create any missing directories in dest(ination) path
        # -- os.path.join is the reverse of split (as you saw above)
        # but it doesn't work with lists... so I had to google how 
        # to use the 'splat' operator! os.makedirs creates missing 
        # directories in a path automatically.
        if len(path) >= 1 and path[0] != '':
            os.makedirs(os.path.join(*path), exist_ok=True)
        
        with open(dest, 'w') as f:
            f.write(filedata)
            
        print(f"Data written to {dest}!")
    
    return dest
        
# Using the `return contents` line we make it easy to 
# see what our function is up to.
src = get_url(url, out)
```

## Decorating!

Let's now look into simplifying this code using a dectorator! Our function has become a bit unwieldy and we want to look at how we can simplify that.

The 'obvious' (i.e. not obvious) way to do this is to implement the check for a local copy as a decorator on the downloading function. So we have a function that downloads, and a decorator function that checks if the download should even be triggered.

```{python}
from functools import wraps
def check_cache(f):
    @wraps(f)
    def wrapper(*args, **kwargs):
        src  = args[0]
        dest = args[1]
        if os.path.isfile(dest):
            print(f"{dest} found locally!")
            return(dest)
        else:
            print(f"{dest} not found, downloading!")
            return(f(src, dest))
    return wrapper

@check_cache
def get_url(src, dest):    
    #Â Get the data using the urlopen function
    response = urlopen(src) 
    filedata = response.read().decode('utf-8')
     
    # Extract the part of the dest(ination) that is *not*
    # the actual filename--have a look at how 
    # os.path.split works using `help(os.path.split)`
    path = list(os.path.split(dest)[:-1])
     
    # Create any missing directories in dest(ination) path
    # -- os.path.join is the reverse of split (as you saw above)
    # but it doesn't work with lists... so I had to google how 
    # to use the 'splat' operator! os.makedirs creates missing 
    # directories in a path automatically.
    if len(path) >= 1 and path[0] != '':
        os.makedirs(os.path.join(*path), exist_ok=True)
     
    with open(dest, 'w') as f:
        f.write(filedata)
         
    print(f"Data written to {dest}!")
    
    return dest
        
# Using the `return contents` line we make it easy to 
# see what our function is up to.
src = get_url(url, out)
```

I'm not going to pretend that's the *best* use of a decorator, but it *does* neatly separate the downloading function from the caching function. In fact, there is already a [cache decorator](https://pvsravanth.medium.com/speeding-up-your-python-code-with-the-cache-decorator-from-functools-bce4731eed69) and some of these have unlimited capacity; however, they are intended to run in a 'live' context, so you'd still need to download the file again any time you start a new notebook or restart Docker. This caching function saves the actual data locally to `dest`.

::: {.callout-warning}

#### Stop! 

It really would be a good idea to put in the effort to make sense of how this function works. There is a lot going on here and understanding how this function works will help you to understand how to code. You should notice that we don't try to check if the data file contains any useful data! So if you download or create an empty file while testing, you won't necessarily get an error until you try to turn it into data afterwards!

:::

## Parse the CSV File

::: {.callout-tip collapse="true"}

#### Difficulty: Low

:::

Now we turn to the next task: parsing the file if it's a CSV. This implies that it *might* not be so that's something we should also consider!

:::: {.qna}

#### Question

```python
import csv

def read_csv(src):
    
    csvdata = []
    with open(src, 'r') as f:
        csvr = csv.??(f)
        
        for r in csvr:
            csvdata.append(??)
    
    # Return list of lists
    return ??

read_csv(src)
#read_csv('foo.bar') # <- Notice what happens if you try to run this code
#read_csv('Practical-04-Objects-Answers.ipynb') # Or this code!
```

#### Answer

```{python}
import csv

def read_csv(src):

    csvdata = []
    with open(src, 'r') as f:
        csvr = csv.reader(f)

        for r in csvr:
            csvdata.append(r)

    # Return list of lists
    return csvdata

read_csv(src)
#read_csv('foo.bar') # <- Notice what happens if you try to run this code
#read_csv('Practical-04-Objects-Answers.ipynb') # Or this code!
```

::::

You should get:

```{python}
#| echo: false
#| output: asis
print("<code>")
print(read_csv(src))
print("</code>")
```

## Convert the CSV into a DoL

::: {.callout-warning collapse="true"}

#### Difficulty: Medium.

:::

Now we can focus on converting the CSV data to a dictionary-of-lists! We're going to start with the *same* function name but expand what the function *does*. This kind of *iteration* is common in software development.

:::: {.qna}

#### Question

```python
def read_csv(src):
    
    csvdata = {} # An empty dictionary-of-lists
    
    with open(??, 'r') as f:
        csvr = csv.reader(f)
        
        #Â Read in our column names and
        # initialise the dictionary-of-lists
        csvcols = next(csvr) 
        for c in csvcols:
            csvdata[c] = []
        
        # Notice this code is still the same, 
        # we just used next(csvr) to get the 
        # header row first!
        for r in ??: 
            # Although you can often assume that the order 
            # of the keys is the same, Python doesn't 
            #Â guarantee it; this way we will always make
            # the correct assignment.
            for idx, c in enumerate(csvcols):
                csvdata[??].append(r[idx])
    
    # Return dictionary of lists
    return csvdata

read_csv(src)
```

#### Answer

```{python}
import csv

def read_csv(src):

    csvdata = {} # An empty dictionary-of-lists

    with open(src, 'r') as f:
        csvr = csv.reader(f)

        #Â Read in our column names and
        # initialise the dictionary-of-lists
        csvcols = next(csvr)
        for c in csvcols:
            csvdata[c] = []

        # Notice this code is still the same,
        # we just used next(csvr) to get the
        # header row first!
        for r in csvr:
            # Although you can often assume that the order
            # of the keys is the same, Python doesn't
            #Â guarantee it; this way we will always make
            # the correct assignment.
            for idx, c in enumerate(csvcols):
                csvdata[c].append(r[idx])

    # Return dictionary of lists
    return csvdata

read_csv(src)
```

::::

You should get something that starts:

```{python}
#| echo: false

print(str(read_csv(src))[:75] + "...")
```

## Adding Docstring

::: {.callout-tip collapse="true"}

#### Difficulty: Low

:::

We've assumed that the first row of our data set is always a _header_ (i.e. list of column names). If it's not then this code is going to have problems. A _robust_ function would allow us to specify column names, skip rows, etc. when we create the data structure, but let's not get caught up in that level of detail. Notice that I've also, for the first time:

1. Used the docstring support offered by Python. You'll be able to use `help(...)` and get back the docstring help!
2. Provided hints to Python about the expected input and output data types. This can help to ensure consistency and is also critical in testing / continuous integration when working with others on a codebase.

```{python}
#| echo: true
def read_csv(src:str) -> dict:
    """
    Converts a CSV file to a dictionary-of-lists (dol),
    using the first row to create column names.
    
    param src: a local CSV file
    returns: a dictionary-of-lists
    """
    csvdata = {} # An empty dictionary-of-lists
    
    with open(src, 'r') as f:
        csvr = csv.reader(f)
        
        #Â Read in our column names and
        # initialise the dictionary-of-lists
        csvcols = next(csvr) 
        for c in csvcols:
            csvdata[c] = []
        
        # Notice this code is still the same, 
        # we just used next(csvr) to get the 
        # header row first!
        for r in csvr: 
            # Although you can often assume that the order 
            # of the keys is the same, Python doesn't 
            #Â guarantee it; this way we will always make
            # the correct assignment.
            for idx, c in enumerate(csvcols):
                csvdata[c].append(r[idx])
    
    # Return dictionary of lists
    return csvdata

ds = read_csv(src)
```

```{python}
help(read_csv)
```

```{python}
print("Columns are: " + ", ".join(ds.keys()))
print(f"First two cities are: {ds['City'][:2]}")
print(f"First two populations are: {ds['Population'][:2]}")
print(f"First two latitudes are: {ds['Latitude'][:2]}")
```

## Creating a Package

We're not going to tackle this now, but it's important that you understand how what we've done connects to what we're *about* to do, and the concept of a package is the bridge. We've already covered this in the pre-recorded lectures, but if you want to actually *try* to create your own package, the simplest way to do this is to:

1. Copy the `read_csv` into a new file called, for instance, `utils.py`.
2. Make sure you delete this function from the current 'namespace' (`del(read_csv)`) by which I mean that the `read_csv` function no longer exists (running `help(read_csv)` should give you an error!).
3. Try importing the function from the file: `from utils import read_csv` and run the `help(read_csv)` code again.

Assuming that you've done everything correctly, we've now brought in code from another file without having to write it into our main Python script file. In Python, many of the most complex libraries are spread across the equivalent of *many* `utils.py` files, but on top of *that* when we import and run them they are also creating objects from classes defined in those files. 

What we now want to do is use a fairly simple example using different 'shapes' (pyramids, cubes, etc.) that allow us to explore how classes work through inheritance from parents and can extend of overwrite the functionality provided by the parent class. We'll need this understanding in order to grasp how Pandas and GeoPandas work specifically, but also how Python works more generally.

# Classes and Inheritance

So, in the immortal words of Monty Python... 

![And now for something completely different](./img/completely_different.png)

::: {.callout-note}

#### &#128279; Connections

This will draw on what you've learned in the lectures about <a href="">Methods</a>, <a href="">Classes</a>, and <a href="">Design</a>. You will also find the Code Camp [Classes](https://jreades.github.io/code-camp/lessons/Classes.html) session useful.

:::

To repeat myself:

> In Python, many of the most complex libraries are spread across the equivalent of *many* `utils.py` files, but on top of *that* when we import and run them they are also creating objects from classes defined in those files. 
>
> What we now want to do is use a fairly simple example using different 'shapes' (pyramids, cubes, etc.) that allow us to explore how classes work through inheritance from parents and can extend of overwrite the functionality provided by the parent class. We'll need this understanding in order to grasp how Pandas and GeoPandas work specifically, but also how Python works more generally.

::: {.callout-caution collapse="true"}

#### Difficulty: &#129327;.

:::

We want to create a set of 'shapes' that allow us to calculate various properties of that shape:

- Diameter: which we'll define as the longest line that can be drawn across the inside of the shape.
- Volume: the total volume of the shape.
- Surface Area: the total outside area of the shape.

We will create all of these shape classes in the notebook so that we know they work and then will move them to an external package file so that they can be imported and re-used easily in other notebooks.

We're also going to make use of a few features of Python:

- You can access the class name of an instance using: `self.__class__.__name__`. And here's one key point: `self` refers to the specific instance (to *this* particular shape that I've created), not to the class in general (to *all* shapes of the same, er, shape)... we'll see why this matters.
- You can raise your own exceptions easily if you don't want to implement a particular method yet. This is giving you control over how your code behaves when something goes 'wrong' -- as we've covered elsewhere sometimes an error is 'expected' and we want to handle the *exception*, other times it is 'unexpected' and we're going to let Python fail so that the user knows something is seriously wrong.
- You can have an 'abstract' base class that does nothing except provide a template for the 'real' classes so that different types of shapes can be used interchangeably. This is quite an advanced feature, but it gives our script a lot more flexibility: we don't need to worry about whether we're working with a sphere, cube, or pyramid (or a spatial or non-spatial data set) because they are defined in a way that allows this flexibility.

## Abstract Base Class

This class appears to do very little, but there are two things to notice:

1. It provides a constructor (`__init__`) that sets the `shape_type` to the name of the class automatically (so a `square` object has `shape_type='Square'`) and it stores the critical dimension of the shape in `self.dim`.
2. It provides methods (which only raise exceptions) that will allow one shape to be used in the place of any other shape that inherits from `shape`.

```{python}
# Base class shape
class shape(object): # Inherit from base class 
    def __init__(self, dimension:float=None):
        self.shape_type = self.__class__.__name__.capitalize()
        self.dim = dimension
        return
    
    def diameter(self):
        raise Exception("Unimplmented method error.")
    
    def volume(self):
        raise Exception("Unimplmented method error.")
    
    def surface(self):
        raise Exception("Unimplmented method error.")
        
    def type(self):
        return(self.shape_type)
```

We can now create a new shape object (an *instance* of the shape class) but we can't do much that is useful with it:

```{python}
s = shape(15)

try: 
    print(f"I am a {s.type()}")
    print(f"My volume is {s.volume()}")
except Exception as e:
    print(f"Error: {e}")
```

## Cube

Implements a cube:

1. The diameter of the cube is given by the Pythagorean formula for the length of the hypotenuse in 3D between opposing corners: $\sqrt{d^{2} + d^{2} + d^{2}}$ which we can reduce to $\sqrt{3 d^{2}}$.
2. A cube's volume is given by $d^{3}$.
3. A cube's surface area will be the sum of its six faces: $6d^{2}$.

:::: {.qna}

#### Question

Can you work out the missing elements that will allow you to create a cube class?

```python
# Cube class
class cube(shape): # Inherit from shape 
    def __init__(self, dim:float):
        super().__init__(dim)
        return
    
    def diameter(self):
        return (3 * self.??**2)**(1/2)
    
    def volume(self):
        return self.dim**3
    
    def surface(self):
        return ??*(self.dim**2)

# If you've done everything correctly then
# you will no longer get an error here...
s = cube(15)

try: 
    print(f"I am a {s.type()}")
    print(f"My volume is {s.volume()}")
except Exception as e:
    print(f"Error: {e}")
```

#### Answer

```{python}
# Cube class
class cube(shape): # Inherit from shape
    def __init__(self, dim:float):
        super().__init__(dim)
        return

    def diameter(self):
        return (3 * self.dim**2)**(1/2)

    def volume(self):
        return self.dim**3

    def surface(self):
        return 6*(self.dim**2)

# If you've done everything correctly then
# you will no longer get an error here...
s = cube(15)

try: 
    print(f"I am a {s.type()}")
    print(f"My volume is {s.volume()}")
except Exception as e:
    print(f"Error: {e}")
```

::::

## Sphere

Implements a sphere:

1. The diameter is twice the critical dimension (radius): $2r$. 
2. The volume is $\frac{4}{3} \pi r^{3}$.
3. The surface area will be $4 \pi r^{2}$.

If we were writing something more general, we'd probably have spheres as a special case of an ellipsoid!

:::: {.qna}

#### Question

Can you work out the missing elements that will allow you to create a cube class?

```python
# Sphere class
from math import pi
class sphere(shape): # Inherit from shape
    def __init__(self, dim:float):
        # Something...

    def diameter(self):
        # Something...

    def volume(self):
        # Something

    def surface(self):
        # Something

# If you've done everything correctly then
# you will no longer get an error here...
s = sphere(15)

try: 
    print(f"I am a {s.type()}")
    print(f"My volume is {s.volume()}")
except Exception as e:
    print(f"Error: {e}")
```

#### Answer

```{python}
from math import pi
# Sphere class
class sphere(shape): # Inherit from shape
    def __init__(self, dim:float):
        super().__init__(dim)
        return

    def diameter(self):
        return self.dim*2

    def volume(self):
        return (4/3) * pi * self.dim**3

    def surface(self):
        return 4 * pi * (self.dim**2)

# If you've done everything correctly then
# you will no longer get an error here...
s = sphere(15)

try: 
    print(f"I am a {s.type()}")
    print(f"My volume is {s.volume()}")
except Exception as e:
    print(f"Error: {e}")
```

::::

## Regular Pyramid

We're taking this to be a regular pyramid where all sides are equal: 

1. The diameter is a line drawn across the base between opposing corners of the base so it's just $\sqrt{d^{2} + d^{2}}$.
2. The volume is given by $VÂ =Â bÂ *Â hÂ /Â 3$ (where $b$ is the area of the base, which in this case becomes $d^{2} * h/3$).
3. The surface area will be the base + 4 equilateral triangles: $d^{2} + 4 (d^{2}\sqrt{3}/4)$ which we can reduce to $d^{2} + d^{2}\sqrt{3}$

But this requires a _height_ method that is specific to pyramids:

4. The height is taken from the centre of the pyramid (which will be half the length of the hypotenuse for two edges): $l = \sqrt{d{^2} + d^{2}}$ and the long side ($d$ again) which gives us $\sqrt{l/2 + d^{2}}$.

::: {.callout-note}

#### Class Variables

Note that this has a **class variable** called `has_mummies` since Egyptian regular pyramids are plagued by them! This class variable is set automatically for *all* instances of the `pyramid` class. Changing this variable can have weird effects so they're not *often* changed.

:::

```{python}
# Pyramid class
class pyramid(shape): # Inherit from shape

    has_mummies = True # This is for *all* regular pyramids

    def __init__(self, dim:float):
        super().__init__(dim)
        self.shape_type = 'Regular Pyramid'
        return

    def diameter(self):
        return (self.dim**2 + self.dim**2)**(1/2)

    def height(self):
        return (self.diameter()/2 + self.dim**2)**(1/2)

    def volume(self):
        return self.dim**2 * self.height() / 3

    def surface(self):
        return self.dim**2 + self.dim**2 * 3**(1/2)
```

## Triangular Pyramid

We have chosen for triangular pyramid to *inherit* from regular pyramid. However, this is kind of a judgement call since there's very little shared between the two types of pyramid and it's arguable whether this one is actually simpler and should therefore be the parent class... 

Just to note, as well, that since all sides are equal this is an _equilateral_ triangular pyramid.  Anyway, the calculations are:

1. The diameter (longest line through the shape) will just be the edge: $d$.
2. The volume $V = b * h / 3$ where $b$ is the area of an equilateral triangle.
3. The surface area will be $4b$ where $b$ is the area of an equilateral triangle.

So we now need two new formulas:

5. The height of the pyramid using ([Pythagoras again](https://www.youtube.com/watch?v=ivF3ndmkMsE)): $h = \sqrt{6}d/3$.
6. The area of an equilateral triangle: $\frac{\sqrt{3}}{4} d^{2}$

Triangular pyramids do *not* have a problem with mummies.

Why don't you add some documentation to this class and the regular pyramid class so that we know how to use them correctly?

```{python}
# Triangular Pyramid class
class t_pyramid(pyramid): # Inherit from regular pyramid

    has_mummies = False # This is for all triangular pyramids

    def __init__(self, dim:float):
        super().__init__(dim)
        self.shape_type = 'Triangular Pyramid'
        return

    def diameter(self):
        return self.dim

    def height(self):
        # h = sqrt(6)/3 * d
        return 6**(1/2)/3 * self.dim

    def base(self):
        return 3**(1/2)/4 * self.dim**2

    def volume(self):
        return (1/3) * self.base() * self.height()

    def surface(self):
        return 4 * self.base()
```

## Testing Your Classes

If you've implemented everything correctly then the following code should run.

```python
# How would you test these changes?
s = sphere(10)
print(s.type())
print(f"\tVolume is: {s.volume():5.2f}")
print(f"\tDiameter is: {s.diameter():5.2f}")
print(f"\tSurface Area is: {s.surface():5.2f}")
print("")

c = cube(10)
print(c.type())
print(f"\tVolume is: {c.volume():5.2f}")
print(f"\tDiameter is: {c.diameter():5.2f}")
print(f"\tSurface Area is: {c.surface():5.2f}")
print("")

p = pyramid(10)
print(p.type())
print(f"\tVolume is: {p.volume():5.2f}")
print(f"\tDiameter is: {p.diameter():5.2f}")
print(f"\tSurface Area is: {p.surface():5.2f}")
print(f"\tHeight is: {p.height():5.2f}")
if p.has_mummies is True:
    print("\tMummies? Aaaaaaaaargh!")
else:
    print("\tPhew, no mummies!")
print("")

p2 = t_pyramid(10)
print(p2.type())
print(f"\tVolume is: {p2.volume():5.2f}")
print(f"\tDiameter is: {p2.diameter():5.2f}")
print(f"\tSurface Area is: {p2.surface():5.2f}")
print(f"\tHeight is: {p2.height():5.2f}")
if p2.has_mummies is True:
    print("\tMummies?Â Aaaaaaaaargh!")
else:
    print("\tPhew,Â noÂ mummies!")
print("")

#Â UsefulÂ demonstrationÂ ofÂ howÂ toÂ findÂ outÂ ifÂ aÂ methodÂ orÂ attributeÂ is
#Â associatedÂ withÂ aÂ particularÂ object
if hasattr(p2,'base_area'):
    print(f"ShapeÂ ofÂ type '{p2.type()}'Â hasÂ attributeÂ orÂ methodÂ 'base_area'")
else:
    print(f"ShapeÂ ofÂ typeÂ '{p2.type()}'Â doesÂ *not*Â haveÂ attributeÂ orÂ methodÂ 'base_area'")
print("")
```

I get the following output:

```{python}
#| echo: false
# How would you test these changes?
s = sphere(10)
print(s.type())
print(f"\tVolume is: {s.volume():5.2f}")
print(f"\tDiameter is: {s.diameter():5.2f}")
print(f"\tSurface Area is: {s.surface():5.2f}")
print("")

c = cube(10)
print(c.type())
print(f"\tVolume is: {c.volume():5.2f}")
print(f"\tDiameter is: {c.diameter():5.2f}")
print(f"\tSurface Area is: {c.surface():5.2f}")
print("")

p = pyramid(10)
print(p.type())
print(f"\tVolume is: {p.volume():5.2f}")
print(f"\tDiameter is: {p.diameter():5.2f}")
print(f"\tSurface Area is: {p.surface():5.2f}")
print(f"\tHeight is: {p.height():5.2f}")
if p.has_mummies is True:
    print("\tMummies? Aaaaaaaaargh!")
else:
    print("\tPhew, no mummies!")
print("")

p2 = t_pyramid(10)
print(p2.type())
print(f"\tVolume is: {p2.volume():5.2f}")
print(f"\tDiameter is: {p2.diameter():5.2f}")
print(f"\tSurface Area is: {p2.surface():5.2f}")
print(f"\tHeight is: {p2.height():5.2f}")
if p2.has_mummies is True:
    print("\tMummies?Â Aaaaaaaaargh!")
else:
    print("\tPhew,Â noÂ mummies!")
print("")

#Â UsefulÂ demonstrationÂ ofÂ howÂ toÂ findÂ outÂ ifÂ aÂ methodÂ orÂ attributeÂ is
#Â associatedÂ withÂ aÂ particularÂ object
if hasattr(p2,'base_area'):
    print(f"ShapeÂ ofÂ type '{p2.type()}'Â hasÂ attributeÂ orÂ methodÂ 'base_area'")
else:
    print(f"ShapeÂ ofÂ typeÂ '{p2.type()}'Â doesÂ *not*Â haveÂ attributeÂ orÂ methodÂ 'base_area'")
print("")
```

## Packaging It Up

Wait, you're *still* working on this practical and haven't thrown up your hands in disgust yet? OK, in that case you can have *one* more thing to do: turn all the shapes into a package that can be loaded via an `import` statement. 

### Cell Magic

This code allows Jupyter to reload external libraries if they are edited after you import them. When you are working on your own packages this is rather useful since you tend to make a *lot* of mistakes when packaging code up this way and it's handy not to have to restart the entire notebook every time you fix a typo or change a function.

```python
%load_ext autoreload
%autoreload 2
```

### Import Shapes

My suggestion is that you create a directory called `shapes` and copy all of the shape code (that's the code for `shape`, `cube`, `sphere`, `pyramid`, `tpyramid`) into a file called `__init__.py` inside the `shapes` directory. You should then able to run the following:

```python
for s in ['shape','sphere','cube','pyramid','t_pyramid']:
    if s in locals():
        del(s)
from shapes import *
```

We need those first three lines of code to delete the existing classes from Python's 'memory' so that we can be sure we're importing the versions we saved to `shapes/__init__.py`.

### Adding Documentation

In an ideal world, this would also be the time to properly document your classes and methods. Here as some examples that you could add to the `__init__.py` package file.

Underneath the line `class shape(object):`, add:

```python
    """Abstract base class for all ideal shape classes.

    Keyword arguments:
    dimension -- the principle dimension of the shape (default None)
    """
```

Underneath the line `def type(self):`, add:

```python
        """
        Returns the formatted name of the shape type. 
        
        This is set automatically, but can be overwritten by setting the attribute shape_type.
        
        :returns: the name of the class, so shapes.cube is a `Cube` shape type
        :rtype: str
        """
```

This would then allow you to run:

```python
from shapes import * # <-- Change this if you didn't call your package `shapes`!
help(shape)
help(shape.type)
```
